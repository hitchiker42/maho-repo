* class 1
* WFF = well formed formula, syntax and semantics
** if A and B are wff's and have the same truth table then A \equiv B
** if A \equiv T; then A is a tautology

* (P \land P \rightarrow Q) \rightarrow Q (if P and P implies Q then Q)
** To show this:
*** Basic: write out truth table
*** Intermediate: solve equation to show (P \land P \rightarrow Q) \rightarrow Q \equiv T

* Atoms and Clauses
** Atoms (A,B,\not A,\not B)
** Clauses (A \lor B, A \land \not{}B, etc..)
** DNF(distrubated normal form) / Full DNF (look up the defn)

* Complete set of operators (can write every possible truth function)
** (e.g \lor and \not, or just nor/nand)

* Logic Systems
** Natural Deduction (Rules)
Not all rules are strictly necesary, but attempt to emulate how
actual deduction works
*** M.P: (Modus Ponens) P and P \rightarrow Q then Q
*** M.T: (Modus Tolens) P \rightarrow Q and \not Q then \not P
*** ADD:  A \rightarrow (A \lor B) , A \rightarrow (B \lor A)
*** CONJ: A, B \rightarrow A \land B
*** D.N: (double negation) \not\not{}A \rightarrow A, and reverse
*** CONT: A \land \not{}A \rightarrow F
*** SIMP: A \land B \rightarrow A, A \land B \rightarrow B
*** D.S: (Disjunctive Syllogism) (A \lor B) \land (\not A) \rightarrow B and reverse
*** C.P: (Conditional Proof) if we can derive B from A then we can say A \rightarrow B

*** H.S: (hypothitical syllogism) A\rightarrow{}B, B\rightarrow{}C, then A\rightarrow{}C
*** C.D: (constructive delema) A \lor B, A\rightarrow{}C, B\rightarrow{}D then C \lor D
*** Cases: A \lor B, A \rightarrow C, B \rightarrow C then C
** Incomplete logic system, has something that is a tautology which can't be proved
** Inconsistant logic system, can prove something that isn't a tautology

** (using C operators here)
prove (A | B) & !A & (B -> C) -> (B & C)
1. (A | B) & !A & (B -> C) P for C.P (premise for conditional proof)
2. A | B, 1 by SIMP
3. !A & B->C, 1 by SIMP
4. !A, 3 by SIMP
5. B->C, 1 by SIMP
6. B, 2,4 by D.S
7. C, 5,6 by M.P
8. B & C, 6,7 by CONJ
9 (A | B) & !A & (B->C) -> (B & C), 1,8 C.P
QED
** simplifications
A & B & C ... & N implies A, B, C, ... N
so still using above
1. A | B, P
2. !A, P
3. B->C, P
4. B, 1,2 D.S
5. C, 3,4, MP
6. B & C, 4,5 CONJ
QED, 1,2,3,6 CP

** (A | B -> C) & A  -> C
1. A|B->C, P
2. A, P
3. A|B, 2, ADD
4. C, 1,3 M.P
QED 1,2,3,4 M.P.
** Proof by Contradiction (I.P)
*** From \not A derive F
*** (A|B)&(B|C)&!C -> A
1. A|B, P
2. B->C, P
3. !C, P
4.     !A, P for I.P. //Start subproof
5.     B, 1,4 D.S
6.     C, 2,5 M.P
7.     F, 3,6 CONT
8. A, 4-7 I.P
QED 1,2,3,8 C.P.

*** (A|B -> C&D) -> (B->D)
1. A|B -> C&D, P for CP
2.           B, P for CP //subproof
3.           A|B, 1,2 by ADD
4.           C&D, by 1,3 MP
5.           D, 4 by SIMP
6. B->D, 2-5 CP
QED 1,6 C.P


# class 2

* Natural Deduction (Rules)
Not all rules are strictly necesary, but attempt to emulate how
actual deduction works
*** M.P: (Modus Ponens) P and P \rightarrow Q then Q
*** M.T: (Modus Tolens) P \rightarrow Q and \not Q then \not P
*** ADD:  A \rightarrow (A \lor B) , A \rightarrow (B \lor A)
*** CONJ: A, B \rightarrow A \land B
*** D.N: (double negation) \not\not{}A \rightarrow A, and reverse
*** CONT: A \land \not{}A \rightarrow F
*** SIMP: A \land B \rightarrow A, A \land B \rightarrow B
*** D.S: (Disjunctive Syllogism) (A \lor B) \land (\not A) \rightarrow B and reverse
*** C.P: (Conditional Proof) if we can derive B from A then we can say A \rightarrow B

*** H.S: (hypothitical syllogism) A\rightarrow{}B, B\rightarrow{}C, then A\rightarrow{}C
*** C.D: (constructive delema) A \lor B, A\rightarrow{}C, B\rightarrow{}D then C \lor D
** Cases: A \lor B, A \rightarrow C, B \rightarrow C then C
* class 2
NOTE: Not all in class examples copied.
* Subproofs
** when using proofs by contradiction or a cp proof within
another cp proof we use a subproof.
Subproofs basically exist within a nested lexical scope in the main proof
and `return` their last line.
ex. (A \lor B \rightarrow C \land D) \rightarrow (B \rightarrow D)
1. A \lor B \rightarrow C \land D, P
 subproof starts here
2.   B, P for CP
3.   A \lor B, 2 ADD
4.   C \land D, 1,3 MP
5.   D, 4 SIMP, Only this line is visable in the main proof
6. B \rightarrow D, 2-5 CP
QED 1,6 CP
* Introduce More Natural Deduction Rules
(also added to Natural Deduction above)
** M.T (Modus Tolens): (P\not{}Q and \not{}Q then \not{}P)
** H.S (hypothitical syllogism) A\rightarrow{}B, B\rightarrow{}C, then A\rightarrow{}C
** C.D (constructive delema) A \lor B, A\rightarrow{}C, B\rightarrow{}D then C \lor D
** Cases: A \lor B, A \rightarrow C, B \rightarrow C then C

* defination of \equiv
** if A \equiv B then
A \rightarrow B and B \rightarrow A
thus if
A \rightarrow B and B \rightarrow A then A \equiv B

** show A \land A \equiv A
we don't have and identity, so this is weird
show A \land A \rightarrow A
1. A \land A, P for C.P
2. A,  SIMP
QED 1-2 CP
show A \rightarrow A \land A
1. A, P for CP
2. A \lor A, 1 add
3. A \land (A \lor A), 1,2 conj
4. A, 3 simp
5. A \land A, 1,4 add
QED 5, CP

* Predicates
** No predicates in natural deduction
so for example,
All A can Q
B can't Q
B isn't A
can't be proven with our current logic
** for a predicate p(x) we can create propisitions in 3 ways
** plug in a value for x, i.e p(1);
** \forall{}x p(x), universal quantification
** \exists{}x p(x), existential quantification
** for this to make sense we need a Domain
i.e where do the values of x come from

* Predicates (second class)
** p(x) is a predicate
when x is filled in with a value it becomes a proposition
** Commonly used symbols
 x,y,z,... variables
 a,b,c,... constants
 p,q,<,>,... predicate names (p(),q() are propisitons, and are written p,q)
 f,g,max,min,+,-.. function names
 \exists, \forall Quantifiers
 punctuation (), ','
a term is a variable or constant or
a function applied to terms

atom is a predicate applied to terms

** predicate wffs
if W and V are wffs then:
 (W),\not{}W, W \land V, W \rightarrow V, etc... are wffs
 \exists{}xW, \forall{}xW are wffs
 predicates, functions, etc..
 combinations of the above

** precedence rules
1: \not \exists \forall
2: \land
3: \lor
4: \rightarrow
binary operators associate left to right
unary operators associate right to left
** Variable rules
the scope of the quantifer \exists{}x \forall{}x in \forall{}xP(x) is P(x)

the 'x' in \exists{}x is the variable the quantifier applies to,
we say that the x is bound to the quantifier. if a variable is not
bound it is free.

we can also bind variables by assigning them a constant value

if a wff has no free variables it is a proposition

in order for \exists{}x and \forall{}x to make sense we must have a
domain of discourse(aka universe)
** Interpretation/Domains
An interpretation of a wff consists of a domain D, together with the following:
assignment of symbols of the wff:
1. each predicate letter is assigned a predicate over D
2. each function lettel is assigned a function over D
3. each constant letter and each free variable is assigned a value in D

ex.
\forall{}x(p(a,x) \rightarrow \not{}q(f(x)))
1. D = N (natural numbers)
   a = 0
   p(z,w) = z < w
   q(w) = w<=2
   f(w) = w+1
\forall{}x(0 < x -> \not (x+1 <= 2))

if W is a wff and x is a free variable in W
(we normally write W(x)) and t is a term
then the wff that results from replacing x with t
is denoted W(x/t)

so the truth value of the wff \forall{}x(W(x)) with respect to the
domain D is:
\forall{}xW(x) is true if W(x/d) is true for all d \epsilon D
ditto  for \exists

** Equivalence
two wffs are equivlent if they are true with respect to every interpretation

since we can't actually test every interpretation we need to prove
that they are equivalent via Natural Deduction

** Rules For quantifiers

\not (\forall{}xW) \equiv \exists{}x \not W
\not (\exists{}xW) \equiv \forall{}x \not W
\exists{}x (p(x) \rightarrow q(x)) \equiv \forall{}x p(x) \rightarrow \exists{}x q(x)

for Q in {\exists,\forall}
QxQy W \equiv QyQx W
Qx(p(x) \lor q(x)) \equiv Qx p(x) \lor Qx q(x)

\exists{}x(p(x) \land \not{}q(x)) \equiv \not\forall{}x(p(x) \rightarrow q(x))

** Quantifier Rules
Universal Instantiation(U.I): \forall{}xW(x) then W(c)(or W(y)); if something is true for everything
it is true for a specific thing

Existential Generalization(E.G): W(c) then \exists{}xW(x)

Extensional Instantiation(E.I): \exists{}xW(x) then W(c) (c is a new unbound symbol
(variable or constant))

Universal Generalization(U.G): W(c) then \forall{}xW(x) (c is an arbitrary symbol)
i.e if something is true for an arbitrary/generalized value it is true for all
values
*** Example
\exists{}x(p(x) \land q(x)) \rightarrow \exists{}xp(x) \land \exists{}xq(x)
1. \exists{}x(p(x) \land q(x)), P for CP
2. p(x) \land q(x), 1 E.I
3. p(x), 2 SIMP
4. q(x), 2 SIMP
5. \exists{}xp(x), 3 E.G
6. \exists{}xq(x), 4 E.G
7. \exists{}xp(x) \land \exists{}xq(x), 5,6 CONJ
QED 1,7 CP
*** Example
\exists{}x(w(x) \rightarrow c) \rightarrow (\forall{}x W(x) \rightarrow c)
1. \exists{}x(w(x) \rightarrow c), P for CP
2.  \forall{}xW(x), P for CP
#Note here, the E.I needs to come before the U.I. in order to
#use the same symbol for both
3.  W(y)->c, E.I. 1
4.  W(y), U.I. 2
5.  C, 3,4 MP
6. \forall{}xW(x) \rightarrow c, 1,6 CP
QED
*** weird note on meanings of different letters
const fun ind dim ?  pred ?     vars
abcde fgh ijk lmn o? pqr  stuv? wxyz
* "Truth"
In propositional logic truth is a tautology

In predicate logic "truth" is validity, a wff is valid if it is true in any
interpretation.

To improve the usefulness of predicate logic we add axioms, i.e \forall{}x = x,
\forall{}x\forall{}y x=y -> y=x

* Proof systems
A system of axioms built on top of predicate logic,

Consistent: you can only prove valid wff's
Complete: you can prove all valid wff's

Generally useful proof systems are consistent but not complete.

* Correctness of Programs

Add all axioms of algebra to default propositional logic.

given a precondition P, a program S and a postcondition Q

{P} S {Q} states that running S when P is true results in Q being true
if S is a correct program

e.g
{x=5} y=x; {y=5}

more formally:
if P is true and S executes and terminates then after S runs Q is true

{Q(x/t)} x:=t {Q} A.A(assignment axiom) (assignment is :=, not = )
ex: {x>0} x := 2 + x {x > 2}

P->R, {R} S {Q} then {P} S {Q}; consequence rule

** ex: prove the following program is correct:
{x<5} x:=x-2 {x < 4}
1. {(x-2)<4 } x:=x-2 {x < 4} A.A
2.    x<5, P for CP
3.    x-1<4, T alg
4.    (x-2)<4, T alg
5. x<5 -> (x-2)<4, 2-4 CP proof
(optional)6. {x<5} x:=x-2 {x<4} 1,5 conquence
QED

** S_1;S_2 \equiv {P} S_1 {R}, {R} S_2 {Q}, then {P} S_1;S_2 {Q} Composition


** ex: {(x>2) \land (y>3)} X:=x+1; y:= y + x {y > 6}
1. {y+x > 6} y:=y+x {y>6} A.A
2. {y+x+1 > 6} x:= x+1 {y+x >6}
3. {y+x+1 > 6} x:=x+1; y = y+x {y  > 6}; 1,2 comp
4.   x>2 \land y>3 P for CP
5.   x+y > 2+3
6.   y+x+1 > 6
6. (x>2) \land (y>3) -> y+x+1 > 6, 4-6 CP
QED 3,7 consequence

** {P\land{}C} S {Q}, (P \land \not{}C) -> Q
{P} if C then S end {Q}

** ex {T} if x<0 then x:=-x end {x>=0} # i.e absolute value
use two proofs, one for each branch
a)1. {-x>=0} x:=-x {x>=0} A.A
  2. T \land x<0, p for cp
  3. x<0 2.simp
  4. -x>0 3.T
  5. -x>=0 4.T
  6. T\land(x<0)-> -x >=0, x-5 cp
  7. (T\land(x<0)) x:=-x {x>=0} 1,6 consequenc
b)1. (T\land\not(x<0)
  2. \not(x<=0)
  3. x>=0
  4. T\land\not(x<0) -> x>=0
QED By a and b and if/then
** {P\land{}C} if C then S_1 else S_2 end {Q} if/then/else
P;
if (C) {
 S_1;
} else {
 S_2;
}
Q;
* Sets
-A set is a collection of objects
-The objects in the set are called elements
-we write x \in A to mean x is an element of A
-"      " x \notin A to mean x is not an element of A
-we say a set contains it's elements
-{} = \empty
- N = natural numbers
- Z = integers
- Q = rationals, ...

-set builder notation
{x | P(x)}, set of elements x such that P(x) is true
i.e P(x) = x > 0, positive integers (assuming the domain is integers)

-two sets A and B are equal iff they contain  (exactly) the same elements.
i.e \forall{}x (x \in A \rightarrow x \in B) \land (x \in B \rightarrow x \in A)

-sets can be arbitrarily nested.
e.g {{\empty},{{\empty}},{{{\empty}}},\empty} is a set containing 4 unique elements.
** Relations
Subsets;
if A and B are sets and \forall{}x(x \in A -> x \in B) (every element in A is also in B)
we say A is a subset of B, A \sube B
\forall{}A, \empty \sube A (or A \supe \empty)

proof:
if A \sube B  and B \sube C then A \sube C
formally: \forall{}x (x \in A \rightarrow x \in B) \land \forall{}x(x \in B \rightarrow x \in C) \rightarrow \forall{}x(x \in A \rightarrow x \in C)
1. \forall{}x(x \in A \rightarrow x \in B), P for CP
2. \forall{}x(x \in B \rightarrow x \in C), P for CP
3. x \in A \rightarrow x \in B, 1. UI
3. x \in B \rightarrow x \in C, 2. UI
5.   x \in A, P
6.   x \in B, 3,5 MP
7.   x \in C, 4,6 MP
8. x \in A \rightarrow x \in C, 5-7 CP
9. \forall{}x(x \in A \rightarrow x \in C), 8 UG.
QED 1,2,9 CP

As a mathmatical proof

if A \sube B and B \sub C then A \sube C
proof: suppose A \sube B and B \sube C
suppose x \in A, since A \sube B, x \in B
since B \sube C then x \in C
thus A \sube C QED

** Power sets
given a set S the power set of S
denoted P(S) is the set of all subsets of S

Given a set of n elements the power set of n will have 2^n elements

ex. suppose A \sube B prove P(A) \sube P(B)
proof: suppose A \sube B, and x \in P(A)
so x \sube A, since x \sube A and A \sube B then x \sube B
thus x \in P(B)
so P(A) \sube P(B) QED

If A and B are sets and
A \sube B and B \sube A then we say the sets are equal and A = B

** Set definations
A \cup B = {x | x \in A \land x \in B}
A \land B = {x | x \in A \lor x \in B}
A - B = {x | x \in A \land x \notin B}
given a domain U
A\prime = {x | x \in U \land x \notin A} = {x | x \notin A}
A\prime is basically the inverse of A, i.e every element in U but not in A
* More Sets
** More Set Properties
A \cup \empty = \empty
A \cap \empty = A
A \cap B = B \cap A
A \cup (B \cap C) = (A \cup B) \cap (A \cup C)
(A \cup B)\prime = A\prime \cap B\prime
(A \cap B)\prime = A\prime \cup B\prime
** Sequences of sets
U_{i=1}^n A_i = {x | \exists{}i x \in A_i}
\cap_{i=1}^n A_i = {x | \forall{}i x \in A_i}
this works for n = \infty
** Weird Sets
A = {A, 0, 1} is a technically correct set, but is kinda weird

if P(x) = x !\in x # x isn't in itself

if D = {S | P(S)}
is D \in D ? this is something of a paradox
This is a flaw in this set theory, which is naive set theory
Axiomatic set theory rectifies this
** Ordered Sets (Tuples)
for n > 0 an N-Tuple (a_1, a_2,...a_n) is a ordered set of n objects a_1,a_2,...a_n.
Two N-Tuples iff each corresponding value is equal. This implies that tuples
can have the set of elements but not be equal.

** Cartesian Product
if A and B are sets the Cartesian product of A and B (written A \times B) is
{(a,b) | a \in A \land b \in B} A \times B is not necessarily equal to B \times A.
If A has n elements and B has k elements A \times B has n*b elements
A \times \empty = \empty
** Functions / Relations
a relation from A to B is a subset of A \times B
a relation from A to A we call a relation on A (this is not the identity)
*** Examples
relation on N
{(x,y) | x \leq y} {(0,0),(0,1),(1,3),(4,8),...}

let A = {a,b,c,d} and R = {(a,c),(b,c),(a,a)}
Digraph (directed graph) (a set of vertexes/nodes/points connected by directed
edges)

** Properties of Relations
Suppose R is a relation on A, we say R is reflexive if for every a \in A we have
(a,a) \in R (i.e R is a superset of the identity on A)

we say R is symmetric if for every (a,b) \in R, we have (b,a) \in R

we say R is transitive if for every  (a,b) \in R and (b,c) \in R we also have
(a,c)\in R

we say R is anti-symmetric if for every (a,b) \in R and (b,a) \in R then a = b
or if a \neq b then (a,b) \notin R \lor (b,a) \notin R

anti-symmetric is not the opposite of symmetric, oddly enough

There is no relation between symmetry and anti-symmetry

Reflexive, symmetric, anti-symmetric and transitive are orthogonal

** operations on relations
various operations on sets (union, intersection...) work on relations.

** Compositions
given a relation R from A to B and a relation S from B to C
than S o R is a relation from A to C (composition)

(R o S)(A)  is the relation created by applying R to the result of S on A.

R o R is perfectly legal.

** Relations/sets -> Matrices
\delta{}A = {(a,a) | a \in A}
 (also called the diagonal (i.e it's the diagonal of a matrix))

If R is a relation define R_0 = \delta and R_n = R_{n-1} o R

When looking at the digraph for R_n it will have all paths of length N
that exist on the digraph of R

We can also represent relations via adjency matrices,
given the relation R on {a,b,c,d} = {(a,a),(a,b),(b,c),(c,d)} we get
the matrix
|   | a | b | c | d |
| a | 1 | 1 | 0 | 0 |
| b | 0 | 0 | 1 | 0 |
| c | 0 | 0 | 0 | 1 |
| d | 0 | 0 | 0 | 0 |

** closures of relations
If R is a relation then the reflexive closure of R written r(R) is the smallest
relation that contains R and is reflexive, this is akin to R U \delta.

the symmetric closure of R, written s(R) is the smallest relation that contains
R and is symmetric

Suppose T is a relation, define T^c = {(a,b) | (b,a) \in T} or T^t (transpose of T)

The simplest way to obtain the symetric closure of R, s(R) is R U R^c.

Finally the transitive closure of R, t(R), is the smallest relation that
contains R and is transitive
t(R) is represented as R U_i^\infty R_i, or from i=0...n if R is a finite set
with n elements

** Warshall algorithm to find the transitive closure
Input: The adjcenty Matrix M for a relation R on 0,1,2,3,...m
Output: The adjancey Matrix for t(R)
given an nxn matrix R, where the i,jth element is set if there is a relation
between i and j in R-
#+BEGIN_SRC c
  int* Warshall(int *R,int n){
    int i,j,k;
    for(k = 0;i<n;i++){
      for(i = 0;j<n;j++){
        for(j = 0;k<n;k++){
          /*
            if(R[i][k] & R[k][j]){
            R[i][j] = 1;
          ,*/
          if(*(R+(i*n)+k) & *(R+(k*n)+j)){
            ,*(R+(i*n)+j) = 1
              }
        }
      }
    }
  }
  /*
    if R is weighted
    if(R[i][j] > R[i][k] + R[k][j]){
    R[i][j] = R[i][k] + R[k][j];
    }
    if(*(R+(i*n)+j ) > (*(R+(i*n)+k)+*(R+(k*n)+j))){
    ,*(R+(i*n)+j) = (*(R+(i*n)+k)+*(R+(k*n)+j));
  */
#+END_SRC


* Missed a class
  Sequences I guess?
* Functions
  A function f is a relation between two sets A and B where each element
in A is mapped to one element of B.

f is injective (an injection) if for every a \in A if a \neq a\prime then f(a) \neq f(a\prime)
  i.e there is a one to one relation between elements of A and B

f is surjective (not subjective) (a surjection)
if for every a \in A there exists a b \in B such that f(a) = b
  this is also known as onto.

if f:A\rightarrow{}B is both surjective and injective that it is bijective (a bijection).

The identity relation \delta:A->A is a Bijection.

if R is a relation  from A to B than R^c in a relation from B to A.
This does not necessarily hold for functions, only for functions that are
bijective. I.e f^-1 exists iff f is bijective.

if f:A->B and g:B->C are functions then g o f:A->C is a function.
if f and g are bijective than g o f is a bijection

** related sets
two sets are related if there is a bijection between them.
the relation R between related sets is Reflexive, Symmetric, and Transitive

* Cardinality
if there is a bjiection f:A->B we say A and B have the same cardinally.


Two finite sets are related iff they have the same number of elements,
by definition they also have the same cardinality.

We say a set A is finite with cardinality K if there exists a bijection
f from A->S_k where S_k = { x | x=0...k }
** Countably infinite sets
We say a set A is infinite but countable if there exists a bijection f:N->A
i.e between the natural numbers and A. It has cardinality \aleph_o

For instance the set of integers Z has a bijection between the natural numbers
of f(N) = {M/2 if m is even; -(M+1)/2 if m is odd}. Thus the set of integers
is countably infinite.

ex. integers, rational numbers, etc...
** Un-countably infinite sets
s:N->{0,1}
S={s | s:N->{0,1}}; the sequence of all possible binary sequences.
Prove S in uncountable
1. Assume S is countable
2. Thus there exists a bijection b:N->S, so we can list S as the union
of (b_i(x) for i \in N) for x \in N.
3. define x-bar as f(x) = (x == 1 ? 0 : 1)
4. define d:N->{0,1} by d_i=b_i-bar
5. Since this is a binary sequence and b is subjective  have some k so that
   b(k)=d
6. but d_k = b(k)_k-bar so d \neq b(k)
7. S is not countable by contridiction.
Essentially if we wrote out the sequences b(x) = b_0(x) b_1(x) b_2(x) ...
in a grid and set d equal to the sequence formed by taking b_i(i) of each
row and inverting it. So d is by definition different than any b and thus
b can't be bijective.

If we let the elements of S be the expantions of real numbers in base 2
this shows real numbers are uncountable.

** Uncountability of infinite power sets
Suppose A is a countably infinite set, show P(A) is uncountable.
1. Since A is countable there exists a bijection x:N->A
2. Let S = {s | s:N->{0,1}}; binary sequences
3. Define b:s->P(A) by b(s) = {x_i | s_i = 1} (b finds a subset of A by creating
   a set containing elements where the corsponding digit in the given binary
   sequenece is set)
-show b is injective
4. Suppose s and s' are binary sequences and s \neq s'
   if we can show b(s) \neq b(s') then it shows P(A) is uncountable
5. since s \neq s' then there exists some k such that s_k \neq s'_k
6. suppose s_k = 1, thus s'_k = 0
7. so  x_k \in b(s) and x_k \notin b(s') so b(s) \neq b(s')
-show b is surjective
8. suppose X \sube A
9. define s:N->{0,1} by {s_i = 1 if x_k \in X; s_i = 0 if x_k \notin X}
10. Thus b is a bjection between P(A) and S
11. Suppose that P(A) is countable
12. Thus there exists a bijection f:N->P(A)
13. So b o f is a bijection from N to S, which is a contridiction
14. Thus P(A) is uncountable

** Pigeon hole principal
if A and B are finite sets and |A| > |B| (more elements in A than B)
then there is no injection from A to B.

i.e if then are n pigeons and k holes and n>k then there must be
at least 2 pigeons in one hole.


* (Mathematical) Strings
  Start with an alphabet \Sigma, a finite nonempty set of (simple) symbols.

  If \Sigma is an alphabet then a finite sequence over \Sigma is called a string

  If X is a string over \Sigma the length of X, written |X|, is the length as a
  sequence.

  Quick note, sequences are always indexed starting at 1.
  A sequence of length n, over \Sigma, is a function from S_n -> \Sigma

  The set of all strings over \Sigma is denoted \Sigma*

  If s \in \Sigma* and |s|=0 then we write s = \Lambda (the empty string)

  Suppose u \in \Sigma* and v \in \Sigma* then concatenation of u and v, written uv
  in the string consisting of the symbols of u followed by the symbols of v.
  uv_i = {u_i if 1 \leq i \leq |u|; v_{i-|u|} if |u|\lt i \leq |u|+|v|

  concatenation identities:
  (uv)w = u(vw)
  \Lambda{}w = w\Lambda = w

  Suppose z \in \Sigma* and z = uvm for u,v,w \in \Sigma* we call v a substring of z,
  any of u,v,w can be \Lambda.

  if z = uw for u,w \in \Sigma* then we call u a prefix, and w a suffix.
** Mathematical Induction (M.I)
   In the domain N (natural numbers)
   to show \forall{}xP(x) it suffices to show that P(0) holds and that
   \forall{}x(P(x)`>P(x+1))

   More generally.
   show P(c) and \forall{}x((x\ge{}c)\rightarrow(P(x)\rightarrow{}P(x+1)) then \forall{}x((x\ge{}c)\rightarrow{}P(x))
** ex
   if k\ge1 then \Sigma_{j=1}^k 2j-1 = k^2
   proof by mathematical induction:
   1. wee will induct over k\ge1
   2. Basis: when k = 1 we have \Sigma_1^1 = 2-1 = 1 = 1^2 = k^2
   3. IH(inductive hypothesis): Assume k\ge2 and arbitary but fixed and suppose
      \sum_{j=1}^{k-1} 2j-1 = k^2
   4. Show \sum_{j=1}^k = k^2, \sum_{j=1}^k =  2k-1 + \sum_{j=1}^{k-1} = 2k-1 + (k-1)^2 = 1 + 2(k-1) + (k-1)^2
      (k+1)(k-1) + 1 = k^2 +k -k -1 + 1 = k^2
** Inductive proof about strings
   suppose w \in \Sigma* define w^k for all k\ge0 by:
   w^0 = \Lambda
   w^k = w^{k-1}w for all k\ge0

   Suppose w \in \Sigma*, show for any k,j\ge0 w^{k}w^{j} = w^{k+j}
   Proof omitted because I was busy fiddling with org sub/superscripts during
   class
** Reversal
   suppose w \in \Sigma*, define w\prime, the reversal of w by:
   w\prime = w iff w = \Lambda
   if |w|>0 Then let w = ua where u \in \Sigma* and a \in \Sigma and then w\prime = au\prime
*** ex
   Prove (uv)\prime = v\prime{}u\prime
   Proof:
   1. variable: will induct on k=|v|\ge0
   2. basis: when k=0 then |v|=0 and (uv)\prime = (u\Lambda)\prime= (u)\prime = \Lambda{}u\prime =
      \Lambda\prime{}u\prime = v\prime{}u\prime
   3. I.H: suppose k\ge0 is arbitrary but fixed and for any string v
      where |v|=k-1 we know (uv)\prime = v\prime{}u\prime
   4. If w is any string and |w| = k, show (uw)\prime=w\prime{}u\prime
   5. Suppose |w|=k then we can write w as va where |v| = k-1 and a \in \Sigma
      We know (uv)\prime = v\prime{}u\prime and w\prime = av\prime, so we can write (uw)\prime as
      (uva)\prime = a(uv)\prime = av\prime{}u\prime = w\prime{}u\prime QED

* Ordering of strings
** dictionary order
  Suppose \Sigma is an alphabet with order <_\Sigma we define the simple
  dictionary order on  \Sigma* as follows:
  for any u,v \in \Sigma* u<v if u\ne{}v and
  1. u is a prefix of v, i.e |u|<|v| and u_i = v_i for i=0...|u|
  2. u = zw and v = zx, x \ne \Lambda where u_i = v_i for i= 0 ... |z| and w_1 < x_1
** Enumeration order
   define the order < on \Sigma* by: for u,v \in \Sigma* u<v if
   1. |u|<|v|
   2. |u| == |v| and u <_D v
* Language
  Suppose \Sigma is a language, \Sigma* is the set of all strings over \Sigma
  A Language L is a set of strings.
  L \sube \Sigma*
  P(\Sigma*) the power set of \Sigma* is the set of all languages

  The C programming language in an infinite set of strings
  A C compiler is a finite string which can determine if another
    finite string is part of the C programming language
  Thus the finite C compiler can represent the infinite C language

  Since \Sigma* has is countably infinite but P(\Sigma*) is uncountably infinite
  the majority of languages can not be represented by finite strings
** Operations on languages
   Given two languages L and M
   L \cup M, L \cap M, L-M, L^c  all have the standard meanings
   L^c = \Sigma* - L, just for reference

   Define the reversal of L, L^R as L^R = {w | w\prime \in L}
   
   Define L o M, or just LM as L o M = {uv | u \in L and v \in M}

   So A\empty = \empty (\empty is {} NOT {\Lambda}) (akin to A * 0)
   And A{\Lambda} = A  (akin to A * 1)

   Association (AB)C = A(BC) = ABC
   
   If A \sube B and C \sube D then AC \sube BC
   A(B \cup C) = AB \cup AC

   Define L^n where n\ge0 as:
   L^0 = {\Lambda} for n = 0
   L^n = L^{n-1}L for n>0

   This implies that \empty^0 = {\Lambda} and \empty^n, n > 0 = \empty
** Powers of languages
   Prove A^m o A^n = A^{m+n} where A is a Language and n,m \in N
   1. induct on n\ge0
   2. when n=0 we have A^n o A^0 = A^n o {\Lambda} = A^n = A^{n+0}
   3. let n be arbitrary but fixed and assume A^{n-1} o A^m = A^{n-1+m}
   4. so A^n o A^m = AA^{n-1} o A^m = AA^{n-1+m} = A^{n+m}
      QED
* Regex
  A is a language
  kleene star closure of A, denoted A^* = {w | w \in A^n for n \ge 0}
  or A^* = U_0^{\infty} L^n
  
  Properties (currently unproven) for languages A and B
  Let A^{**} = (A^*)^*
  1. A \sube AB^* (trivial proof, \Lambda \in B, A{\Lambda} = A, QED)
  2. A \sube B \rightarrow A^* \sube B^*
  3. A^*A^* = A^*
  4. A^* \sube A^{**}  (true from defn of kleene star)
  5. (A^*)^n \sube A^*
  6. A^{**} \sube A^* ((A^*)^n \sube A^{**} by defn and (A^*)^n \sube A^* so A^{**} \sube A^*)
  7. {\Lambda} \cup AA^* = A^*
     
  To prove things about kleene stars change A^* to A^k for arbitrary k \ge 0
  2.
  Show A \sube B \rightarrow A^* \sube B^*
  Suppose w \in A^*
  We have k\ge0 with w \in A^k
  Since A \sube B we know A^k \sube B^k
  so w \in B^k and thus w \in B^* QED
  
  3.
  Show A^*A^* = A^*
    show A^*A^* \sube A^*
    suppose w \in A^*A^*, so w = vu where v \in A^* and u \in A^*
    so we have k,l such that v \in A^k and u \in A^l
    so w = vu \in (A^k A^l = A^{k+l} so w \in A^* QED
  now
    show A^* \sube A^*A^*
    from property #1 this is true.
  so A^*A^* \sube A^* and A^* \sube A^*A^*, thus A^*A^* = A^* QED
    
  5.
  show (A^*)^n \sube A^*
  induct on n
  (A^*)^0 = {\Lambda} \sube A^*
  Assume (A^*)^{n-1} \sube A^*
  Show (A^*)^n \sube A^*; (A^*)^n = (A^*)^{n+1-1} = A^*A^{n-1}
  Since A^{n-1} \sube A^* then A^n = A^*A^{n-1} \sube A^*A^* = A^* so A^n \sube A^*

  7.
  Show {\Lambda} \cup AA^* = A^*
  A^0 = {\Lambda}
  AA^* = AU_0^{\infty} A^n = U_1^{\infty} 

* Local Variables
# Local Variables:
# eval: (auto-fill-mode)
# eval: (flyspell-mode)
# eval: (org-cdlatex-mode)
# org-pretty-entities: t
# org-enable-table-editor: nil
# End:
